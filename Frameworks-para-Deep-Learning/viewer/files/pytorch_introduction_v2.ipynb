{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch\n",
    "### - Introdução a manipulação de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução ao PyTorch\n",
    "- O que é o PyTorch?\n",
    "    - É um framework de ML/DL baseado em Torch (Lua e C++)\n",
    "    - Aplicações em VC, NLP, Audio, Video, ...\n",
    "    - Desenvolvido pelo time de IA do Facebook\n",
    "    - Lançamento: setembro de 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução ao PyTorch\n",
    "- Empresas que usam o framework:\n",
    "    - Toyota Research Institute\n",
    "    - Airbnb, Salesforce\n",
    "    - Duolingo [link](https://aws.amazon.com/pt/machine-learning/customers/innovators/duolingo/)\n",
    "    - Lift [link](https://medium.com/pytorch/how-lyft-uses-pytorch-to-power-machine-learning-for-their-self-driving-cars-80642bc2d0ae)\n",
    "    - Disney [link](https://medium.com/pytorch/how-disney-uses-pytorch-for-animated-character-recognition-a1722a182627)\n",
    "    - Pixar [link](https://venturebeat.com/business/how-pixar-uses-ai-and-gans-to-create-high-resolution-content/)\n",
    "    - Nasa [link](https://thenewstack.io/nasa-and-ibm-to-speed-ai-creation-with-new-foundation-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução ao PyTorch\n",
    "- Alguns modelos recentes:\n",
    "    - GPT-2, GPT-3\n",
    "    - Whisper [link](https://github.com/openai/whisper)\n",
    "    - Lhama [link](https://github.com/meta-llama/llama)\n",
    "    - Transformer e BERT \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's do it\n",
    "\n",
    "<img src=\"img/png/letsdoit.png\" width=\"400\" height=\"150\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensor\n",
    "<img src=\"img/png/neuralnet.png\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensor\n",
    "- O que é um tensor?\n",
    "    - \"*Is just a generic n-dimensional array to be used for arbitrary numeric computation*\"\n",
    "    - Generalização de uma estrutura de dados n-dimensional\n",
    "- Aplicações na engenharia e física: será que são tão diferentes assim?\n",
    "    - Tensor de tensões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Principais diferenças entre ```torch.tensor``` e ```np.ndarray```\n",
    "\n",
    "- Apesar de ambos armazenarem matrizes n-dimensionais \n",
    "- ```torch.tensors``` tem uma \"camada\" adicional \n",
    "- Armazena o grafo computacional que leva tensor associado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Olhando o tensor em si são basicamente iguais\n",
    "- Tensores podem ser facilmente enviados para GPU\n",
    "- Numpy arrays também podem, mas não de forma nativa: PyCUDA e CuPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensores - Dimensões\n",
    "<img src=\"img/tensor.png\" width=\"724\" height=\"121\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensores - Dimensões\n",
    "\n",
    "- Exemplos\n",
    "    - 1D: vetor linha/coluna\n",
    "    - 2D: matriz\n",
    "    - 3D: imagem\n",
    "    - 4D: batch de imagens, vídeo\n",
    "    - 5D: batch de vídeos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Criação de um tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([[40,80,30], [50,90,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tipos de tensores\n",
    "Em PyTorch, temos os seguintes tipos de tensores\n",
    "- Ponto flutuante (float): 16, 32 e 64 bits\n",
    "- Inteiro (int): 8, 16, 32 e 64 bits\n",
    "- Números complexos (complex): 32, 64 e 128 bits\n",
    "- Booleano (bool)\n",
    "- Complexo (parte real + imaginária)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conversão entre tipos de tensores\n",
    "- Os tensores em PyTorch podem ser convertidos entre os diversos formatos\n",
    "- A maneira mais simples é com a chamada do método referente ao tipo desejado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Operações Matemáticas\n",
    "- Adição\n",
    "- Subtração\n",
    "- Multiplicação\n",
    "- Divisão\n",
    "\n",
    "Essas operações são element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adição de tensores\n",
    "- Método ```add(a,b)``` realiza a soma dos tensores $\\mathbf{a}$ e $\\mathbf{b}$, elemento por elemento: $a_{i,j} + b_{i,j}$ \n",
    "- Inicializando os tensores $\\mathbf{a}$ e $\\mathbf{b}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1,2], [3,4]])\n",
    "b = torch.Tensor([[5,6], [7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiplicação de Tensores\n",
    "As próximas operações merecem uma atenção especial.\n",
    "- Vimos como multiplicar dois tensores, elemento por elemento\n",
    "- Mas como fazer realmente a multiplicação matricial?\n",
    "- Para efetuar essa operação temos o método ```mm``` (matrix multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Vamos considerar os tensores $\\mathbf{a}$, $\\mathbf{b}$ e $\\mathbf{c}$ abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.Tensor([[0,1,3],[1,0,2]]).t()\n",
    "c = torch.Tensor([1,1,2])\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Realizando a multiplicação entre as matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E esse multiplicarmos o tensor $\\mathbf{a}$ pelo tensor $\\mathbf{c}$ (vetor) usando o método ```mm```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para esse tipo de situação o PyTorch tem o método ```mv``` que multiplica uma matriz por um vetor (matrix - vector).\n",
    "\n",
    "Assim é possível multiplicar o tensor $\\mathbf{a}$ pelo tensor $\\mathbf{c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quem lembra um pouco de Álgebra Linear?\n",
    "- Não precisam assustar, mas nas aulas de Álgebra Linear fazíamos um chamado __produto escalar__\n",
    "- Quem lembra como era calculado?\n",
    "- Dados dois tensores\n",
    "- $\\mathbf{A} = (a_1, a_2, \\cdots, a_n)$\n",
    "- $\\mathbf{B} = (b_1, b_2, \\cdots, b_n)$\n",
    "- O produto escalar $\\mathbf{A} \\cdot \\mathbf{B}$ é dado por $\\sum_{k=1}^{n} = a_i b_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- No PyTorch temos o método ```dot``` para realizar o produto escalar\n",
    "- Pode ser usado o símbolo ```@``` no lugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Curiosidade__: A multiplicação de matrizes $\\mathbf{X}$ e $\\mathbf{Y}$ é o produto escalar das linhas de $\\mathbf{X}$ pelas colunas de $\\mathbf{Y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Manipulação de Tensores\n",
    "\n",
    "O PyTorch também fornece algumas outras manipulações importantes sobre os tensores\n",
    "- ```view```: altera a forma de visualizar o tensor sem alterá-lo\n",
    "- ```cat``` : concatena tensores\n",
    "- ```chunck```: quebra o tensor\n",
    "- ```squeeze```: espreme o tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### View\n",
    "Alterando a visualização dos tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1,2,3,4,5,6,7,8,9])\n",
    "b = torch.Tensor([1,2,3,4])\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cat\n",
    "Concatenando tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chunk\n",
    "Quebra o tensor em parte iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Squeeze\n",
    "Espreme o tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução ao PyTorch - Parte 2\n",
    "- O que vamos ver?\n",
    "    - Aplicação em uma Regressão Linear\n",
    "    - Algumas estruturas básicas para treinar um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- O que é uma Regressão Linear?\n",
    "    \n",
    "    \"*A regressão linear quantifica a relação entre uma ou mais variáveis preditoras e uma variável de resultado*\"\n",
    "    \n",
    "    \n",
    "- Matematicamente, queremos definir:\n",
    "\n",
    "   - $\\hat{y} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\cdots + \\theta_nx_n$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " - em que:\n",
    "     - $\\hat{y}$: valor previsto\n",
    "     - $n$: número de features\n",
    "     - $x_i$: é o valor da i-ésima feature\n",
    "     - $\\theta_j$: é o parâmetro $j$ do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Olhando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('exp_vs_salary_data.csv')\n",
    "data.columns = ['anos_experiencia', 'salario']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vendo algumas informações adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(data.anos_experiencia, data.salario)\n",
    "plt.xlabel(\"Anos de Experiência\")\n",
    "plt.ylabel(\"Salário\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vendo a correlação entre os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sepando dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data,  test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quem ainda lembra dos tensores?\n",
    "- Uma vez tendo separado os dados para treino e teste;\n",
    "- Precisamos converter o dado para o formato aceitável pelo PyTorch;\n",
    "- Nesse ponto, voltamos aos tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Convertendo os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "y_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convertendo os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =\n",
    "y_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train.view(6,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.view(6,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Novas estruturas\n",
    "- Muitas vezes necessitamos que:\n",
    "    - Código que gera/pré-processa os dados de treino esteja desacoplado do treino do modelo;\n",
    "    - O que gera:\n",
    "        - Melhor modulariação e legibilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Novas estruturas\n",
    "\n",
    "- Nesse momento vamos apresentar duas novas estruturas do PyTorch:\n",
    "    - __Dataset__: armazena as amostras e os rótulos (usaremos o TensorDataset neste ponto);\n",
    "    - __DataLoader__: envolve um iterável em torno do Dataset (fácil acesso às amostras - batch), retorna X,y.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Novas estruturas\n",
    "Dentre os Datasets disponíveis no módulo ```torch.util.data``` existe um de grande utilidade ```IterableDataset```\n",
    "- Usado para streaming de dados\n",
    "- Para conjunto de dados grandes\n",
    "\n",
    "__Observação__: Datasets e DataLoaders podem ser customizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Novas estruturas\n",
    "- Algumas outras estruturas que ainda faltaram:\n",
    "    - __Modelo__ (```nn.Linear```): rede que será treinada (propriamente dita);\n",
    "    - __Função de Perda__ (```nn.MSELoss```): quem calcula o quanto o modelo erra;\n",
    "    - __Otimizador__ (```torch.optim```): quem atualiza os pesos da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = ...\n",
    "loss_fun = ...\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pergunta:\n",
    "- Repararam algum parâmetro diferente nos tensores anteriores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Nos parâmetros apareceu um \"requires_grad=True\", qual a utilidade disso?\n",
    "- O parâmetro ```requires_grad=True``` indica que os gradientes podem ser calculados para o tensor;\n",
    "- Não significa que eles irão ser calculados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exemplo\n",
    "\n",
    "Consideremos os seguintes tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos criar um tensor $Q$ a partir de $a$ e $b$ da seguinte forma:\n",
    "- $Q = 3a^3 - b^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Operador Gradiente\n",
    "Quem se lembra das derivadas?\n",
    "- __Gradiente de uma função__: vetor que aponta na direção de crescimento;\n",
    "- $\\vec \\nabla f_{(x_1, x_2, \\cdots, x_n)} = \\left \\langle \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\cdots, \\frac{\\partial f}{\\partial x_n} \\right \\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Operador Gradiente\n",
    "\n",
    "- Qual o motivo de usarmos os gradientes?\n",
    "    - Otimizadores\n",
    "    - Atualização dos pesos da rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Operador Gradiente\n",
    "\n",
    "- Como ficaria o gradiente de $Q$?\n",
    "- $\\vec \\nabla Q = \\left \\langle \\frac{\\partial Q}{\\partial a}, \\frac{\\partial Q}{\\partial b} \\right \\rangle =\\left \\langle 9a^2, -2b\\right \\rangle$\n",
    "- Calculando o gradiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__IMPORTANTE__: Quando estamos calculando os gradientes no treino de um modelo, não há necessidade de passar o tensor $v$, a função de perda já o fornece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vendo os gradientes armazenados nos tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Voltando ao modelo\n",
    "- Vimos anteriormente como criar um otimizador, a função de perda (com os gradientes) e o modelo;\n",
    "- Podemos ter uma segunda forma de criar o modelo definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Anteriormente criamo o modelo usando apenas a seguinte linha de comando:    \n",
    "    ``` model = nn.Linear(1, 1)```\n",
    "    \n",
    "- Caso seja necessário criar modelos mais complexos, o PyTorch fornece uma forma usando OO:\n",
    "    - Criar uma classe que herde da classe ```nn.Module```\n",
    "    - Deve-se implementar o método ```forward()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classe para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        ...\n",
    "    \n",
    "    def forward(self, X):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Função para treino do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(num_epochs, model, loss_fun, optimizer, train_dataloader):\n",
    "    \n",
    "    \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1,\n",
    "                                                       num_epochs,\n",
    "                                                       loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "O laço mais interno dentro da função de treino, apresenta 5 passos fundamentais para o treino:\n",
    "- (1) avaliação dos dados pelo modelo: ```pred = model(xb)```\n",
    "- (2) cálculo da perda (erro): ```loss = loss_fun(pred, yb)```\n",
    "- (3) cálculo do gradiente: ```loss.backward()```\n",
    "- (4) atualização dos pesos: ```optimizer.step()```\n",
    "- (5) reset dos gradientes: ```optimizer.zero_grad()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__IMPORTANTE__: \n",
    "- Os 5 passos anteriores devem ser executados para cada batch de dados que forem gerados em uma época;\n",
    "- Por isso temos os loops aninhados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agora sim, vamos ao treino do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "num_epochs=100\n",
    "train_model(num_epochs, model, loss_fun, optimizer, train_dataloader)\n",
    "preds = model(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parametros após o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.weight.item()\n",
    "b = model.bias.item()\n",
    "print('Weight: ', a)\n",
    "print('Bias: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plotando a Regressão\n",
    "- Nesta parte vamos ver a regressão que o modelo treinado gerou\n",
    "- Mas antes, vamos usar os parâmetros para construir a equação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.0, 12, 0.01)\n",
    "y = a*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uma outra forma de obtermos os valores de y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.Tensor(x).unsqueeze(1)\n",
    "model(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Plot da Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.anos_experiencia, data.salario)\n",
    "plt.plot(x, y, color='orange')\n",
    "plt.xlabel(\"Anos de Experiência\")\n",
    "plt.ylabel(\"Salário\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resumo\n",
    "Tivemos contato com alguns pontos novos do PyTorch:\n",
    "- Dataset e DataLoader;\n",
    "- Modelo, Função de perda e Otimizador;\n",
    "- Entendemos como são calculados os gradientes;\n",
    "- 5 passos que devem estar dentro do ciclo de treino de um modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Referências\n",
    "- Documentação sobre Datasets e DataLoaders https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "- Documentação sobre tensores (https://pytorch.org/docs/stable/tensors.html)\n",
    "- (Livro) Deep Learning With PyTorch: Build, Train, and Tune Neural Networks (2021)(https://www.amazon.com.br/Deep-Learning-Pytorch-Eli-Stevens/dp/1617295264)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- (Livro) Deep Learning with PyTorch-Packt (2018)(https://github.com/yangyutu/bigfiles/blob/master/Vishnu%20Subramanian%20-%20Deep%20Learning%20with%20PyTorch-Packt%20(2018).pdf)\n",
    "- (Livro) Deep Learning With Python (2018) (https://www.amazon.com.br/Deep-Learning-Python-Francois-Chollet/dp/1617294438/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
