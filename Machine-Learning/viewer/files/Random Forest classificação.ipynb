{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkXayBrgn61g2rD1WgxDfI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Random Forest\n","---\n","**Aula Prática 07**: RandomForest para classificação\n","\n","\n","**Objetivo**: Treinar modelo de classificação\n","\n","\n","Banco de dados:\n","\n","\n","**Breast cancer wisconsin dataset**\n","\n","\n","Disponível via sklearn\n","\n","\n","> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.\n",">\n","> 1) ID number\n",">\n","> 2) Diagnosis (0 = malignant, 1 = benign)\n",">\n","> 3-32)\n",">\n","> Ten real-valued features are computed for each cell nucleus:\n",">\n","> a) radius (mean of distances from center to points on the perimeter)\n",">\n","> b) texture (standard deviation of gray-scale values)\n",">\n","> c) perimeter\n",">\n","> d) area\n",">\n","> e) smoothness (local variation in radius lengths)\n",">\n","> f) compactness (perimeter^2 / area - 1.0)\n",">\n","> g) concavity (severity of concave portions of the contour)\n",">\n","> h) concave points (number of concave portions of the contour)\n",">\n","> i) symmetry\n",">\n","> j) fractal dimension (\"coastline approximation\" - 1)"],"metadata":{"id":"zxHUgPSFM1fc"}},{"cell_type":"markdown","source":["##Import das principais funções e leitura dos dados\n","\n","\n","---\n","\n"],"metadata":{"id":"w1NLIkJMRP4U"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import datasets"],"metadata":{"id":"Wfg5H5k7QUoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = datasets.load_breast_cancer()"],"metadata":{"id":"cz13V0q4Q5ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(data.data, columns=data.feature_names)"],"metadata":{"id":"39H8czgiIvdT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target = pd.DataFrame(data.target, columns=['Target'])\n","df = pd.concat([df, target], axis=1)"],"metadata":{"id":"do_VDG4RJICz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"gE2hH2_8SHHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"K94v4s0lSNC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"iyj0P08tSR5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe().T"],"metadata":{"id":"D4JMYa2ZJSto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Treino de modelo de decision tree\n","---\n","\n","\n","Para treinar um modelo de regressão utilizaremos o pacote sklearn.\n","\n","\n","### Separação do banco entre treino e teste\n","O primeiro passo para se treinar um modelo é separar o banco entre treino e teste. Para isso utilizaremos a função train_test_split\n","\n","\n","``` python\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n","```\n","No exemplo acima X é um dataframe contendo as features do modelo e Y um dataframe com a variável target.\n","\n","\n","O parâmetro test_size controla o percentual de dados que será utilizado para teste.\n","\n","\n","O parâmetro random_state controla a aleatoriedade da geração do dado, permitindo que ao reexecutar o código seja gerado os mesmos bancos de treino e teste.\n","\n","\n","É importante separar o banco entre treino e teste, pois utilizaremos o banco de treino para treinar modelos e o banco de teste para avaliar os modelos.\n","\n","\n","### Treino do modelo\n","Agora que já possuímos os dados de treino e teste vamos treinar o nosso modelo Random Forest\n","\n","\n","``` python\n","from sklearn.ensemble import RandomForestClassifier\n","model = RandomForestClassifier()\n","model.fit(X_train, Y_train)\n","```\n","\n","No código acima o objeto model é do tipo RandomForestClassifier, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado a árvore e a importancia das features.\n","\n","\n","``` python\n","# Para fazer predições de classes\n","model.predict(X_test)\n","# Para fazer predições de probabilidade\n","model.predict_proba(X_test)\n","# Para acessar a importancia\n","model.feature_importances_\n","\n","```\n","\n","Alguns parâmetros da Random Forest:\n","* criterion: critério para quebra de um nó. Default é gini, mas também pode ser entropy e log_loss\n","* max_depth: profundidade da árvore. Default é None, isso faz com que as folhas sejam puras (observações menor que min_samples_split)\n","* min_samples_split: minimo de amostra para separação. Default: 2\n","* min_samples_leaf: Minimo de amostras em cada folha. Só será considerado quebra com no minimo esse tamanho de amostra. Default: 1.\n","* random_state: semente para aleatoriedade.\n","* n_estimators*: número de árvores para construir. Default: 10\n","\n","\n","### Avaliação do modelo\n","Para avaliar o modelo treinado utilizaremos as métricas vistas na aula teórica.\n","\n","``` python\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay\n","\n","\n","# Métricas acurácia, precisão, recall, f1-score\n","print(classification_report(Y_test, Y_predit))\n","\n","\n","# Matriz de confusão\n","confusion_matrix(Y_test, Y_predit)\n","\n","\n","# AUC\n","roc_auc = roc_auc_score(Y_test, Y_predict)\n","fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n","display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n","display.plot()\n","```\n","\n","\n","Também é possível se obter cada uma das métricas do report\n","``` python\n","from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n","\n","\n","recall_score(Y_test, Y_predict, pos_label=1)\n","```\n","\n","\n","### Primeiro modelo\n","\n","---\n","\n","Exercício:\n","\n","\n","* Separe o banco entre treino e teste. Use 30% do banco para teste. Faça a quebra com todas as variáveis.\n","* Treine um modelo.\n","* Faça as análises de apuração do modelo\n"],"metadata":{"id":"M9mSwwoqRbef"}},{"cell_type":"code","source":["X = pd.DataFrame(data.data, columns=data.feature_names)\n","Y = data.target"],"metadata":{"id":"G4pgJuxgN_XX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solução"],"metadata":{"id":"idl1fuKB-1TJ"}},{"cell_type":"code","source":[],"metadata":{"id":"UsSPmITem8gH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercício:\n","* Treine um novo modelo porém com max_depth = 4\n","* Busca o limiar em que se obtém a melhor acurácia.\n","\n","Dica:\n","Para realizar a busca faça:\n","1. Gere o score de probabilidade\n","2. Percorra uma lista de valores de limiar e a cada valor calcule a acurácia\n","3. Obtenha o limiar com maior acurácia\n","\n","\n","Para acessar P(Y=1) faça predict_proba()[:, 1]"],"metadata":{"id":"sztPnLqBUBm4"}},{"cell_type":"markdown","source":["#### Solução"],"metadata":{"id":"265K8AE9UgWU"}},{"cell_type":"markdown","source":["**Visualização da feature importance**"],"metadata":{"id":"92XsDKG0rGC2"}},{"cell_type":"code","source":["df = pd.DataFrame(model.feature_importances_.T, index=data.feature_names, columns=['Importancia'])\n","df.sort_values('Importancia', ascending=False)"],"metadata":{"id":"mPM9tPBGrv9H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.bar(df.sort_values('Importancia'))"],"metadata":{"id":"K9v9YUWYsWd0"},"execution_count":null,"outputs":[]}]}