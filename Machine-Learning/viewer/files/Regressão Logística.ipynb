{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNW7jiITGVie8Lzbnvlipnr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Regressão Logística\n","---\n","**Aula Prática 04**: Regressão Logística\n","\n","\n","**Objetivo**: Treinar modelo de classificação\n","\n","\n","Banco de dados:\n","\n","\n","**Breast cancer wisconsin dataset**\n","\n","\n","Disponível via sklearn\n","\n","\n","> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.\n",">\n","> 1) ID number\n",">\n","> 2) Diagnosis (0 = malignant, 1 = benign)\n",">\n","> 3-32)\n",">\n","> Ten real-valued features are computed for each cell nucleus:\n",">\n","> a) radius (mean of distances from center to points on the perimeter)\n",">\n","> b) texture (standard deviation of gray-scale values)\n",">\n","> c) perimeter\n",">\n","> d) area\n",">\n","> e) smoothness (local variation in radius lengths)\n",">\n","> f) compactness (perimeter^2 / area - 1.0)\n",">\n","> g) concavity (severity of concave portions of the contour)\n",">\n","> h) concave points (number of concave portions of the contour)\n",">\n","> i) symmetry\n",">\n","> j) fractal dimension (\"coastline approximation\" - 1)"],"metadata":{"id":"zxHUgPSFM1fc"}},{"cell_type":"markdown","source":["##Import das principais funções e leitura dos dados\n","\n","\n","---\n","\n"],"metadata":{"id":"w1NLIkJMRP4U"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import datasets"],"metadata":{"id":"Wfg5H5k7QUoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = datasets.load_breast_cancer()"],"metadata":{"id":"cz13V0q4Q5ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(data.data, columns=data.feature_names)"],"metadata":{"id":"39H8czgiIvdT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target = pd.DataFrame(data.target, columns=['Target'])\n","df = pd.concat([df, target], axis=1)"],"metadata":{"id":"do_VDG4RJICz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"gE2hH2_8SHHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"K94v4s0lSNC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"iyj0P08tSR5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe().T"],"metadata":{"id":"D4JMYa2ZJSto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Treino de modelo de regressão Logística\n","---\n","\n","\n","Para treinar um modelo de regressão utilizaremos o pacote sklearn.\n","\n","\n","### Separação do banco entre treino e teste\n","O primeiro passo para se treinar um modelo é separar o banco entre treino e teste. Para isso utilizaremos a função train_test_split\n","\n","\n","``` python\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n","```\n","No exemplo acima X é um dataframe contendo as features do modelo e Y um dataframe com a variável target.\n","\n","\n","O parâmetro test_size controla o percentual de dados que será utilizado para teste.\n","\n","\n","O parâmetro random_state controla a aleatoriedade da geração do dado, permitindo que ao reexecutar o código seja gerado os mesmos bancos de treino e teste.\n","\n","\n","É importante separar o banco entre treino e teste, pois utilizaremos o banco de treino para treinar modelos e o banco de teste para avaliar os modelos.\n","\n","\n","### Treino do modelo\n","Agora que já possuímos os dados de treino e teste vamos treinar o nosso modelo de regressão para isso utilizaremos o módulo LogisticRegression\n","\n","\n","\n","\n","``` python\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression(penalty='none')\n","model.fit(X_train, Y_train)\n","```\n","\n","\n","No código acima o objeto model é do tipo LogisticRegression, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado nele os coeficientes do modelo.\n","\n","\n","``` python\n","# Para acessar os coeficientes\n","model.coef_\n","# Para acessar o intercepto\n","model.intercept_\n","# Para fazer predições de classes\n","model.predict(X_test)\n","# Para fazer predições de probabilidade\n","model.predict_proba(X_test)\n","```\n","\n","\n","### Avaliação do modelo\n","Para avaliar o modelo treinado utilizaremos as métricas vistas na aula teórica.\n","\n","\n","\n","\n","``` python\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay\n","\n","\n","# Métricas acurácia, precisão, recall, f1-score\n","print(classification_report(Y_test, Y_predit))\n","\n","\n","# Matriz de confusão\n","confusion_matrix(Y_test, Y_predit)\n","\n","\n","# AUC\n","roc_auc = roc_auc_score(Y_test, Y_predict)\n","fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n","display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n","display.plot()\n","```\n","\n","\n","Também é possível se obter cada uma das métricas do report\n","``` python\n","from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n","\n","\n","recall_score(Y_test, Y_predict, pos_label=1)\n","```\n","\n","\n","### Primeiro modelo\n","\n","\n","\n","\n","---\n","\n","\n","\n","\n","Exercício:\n","\n","\n","* Separe o banco entre treino e teste. Use 30% do banco para teste. Faça a quebra com todas as variáveis.\n","\n","\n","* Treine um modelo.\n","* Qual a interpretação do coeficiente para mean radius?\n","* Qual a interpretação do coeficiente para mean concavity?\n","* Faça as análises de apuração do modelo\n","\n","\n","Dica:\n","\n","\n","Para se obter um dataframe com os coeficientes e seus respectivos nomes faça:\n","\n","\n","``` python\n","pd.DataFrame(model.coef_.T, index=X_train.columns)\n","```"],"metadata":{"id":"M9mSwwoqRbef"}},{"cell_type":"code","source":["X = pd.DataFrame(data.data, columns=data.feature_names)\n","Y = data.target"],"metadata":{"id":"G4pgJuxgN_XX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fXFhf4YQheuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercício:\n","\n","* Busca o limiar em que se obtém a melhor acurácia.\n","\n","Dica:\n","Para realizar a busca faça:\n","1. Gere o score de probabilidade\n","2. Percorra uma lista de valores de limiar e a cada valor calcule a acurácia\n","3. Obtenha o limiar com maior acurácia\n","\n","\n","Para acessar P(Y=1) faça predict_proba()[:, 1]"],"metadata":{"id":"sztPnLqBUBm4"}},{"cell_type":"code","source":[],"metadata":{"id":"j11JH7xihcfo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercício:\n","\n","\n","* Construa um gráfico que analise os valores de precisão, recall e f1 score para cada limiar.\n","\n","\n","Dica:\n","Para realizar a busca faça:\n","1. Gere o score de probabilidade\n","2. Percorra uma lista de valores de limiar e a cada valor calcule as métricas e salve em uma lista\n","\n","\n","Construa um dataframe através dessa lista\n","\n","Utilize a função de line do plotly.express para gerar o gráfico.\n","\n","\n","``` python\n","import plotly.express as px\n","px.line(df, x='limiar', y=['precisao', 'recall', 'f1'])\n","```"],"metadata":{"id":"CiWAhbMEXZAp"}},{"cell_type":"code","source":[],"metadata":{"id":"nExcHj_ahrTu"},"execution_count":null,"outputs":[]}]}