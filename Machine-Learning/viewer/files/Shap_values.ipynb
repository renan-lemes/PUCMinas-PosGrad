{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#SHAP\n",
        "---\n",
        "**Aula Prática 18**: SHAP Values\n",
        "\n",
        "\n",
        "**Objetivo**: Interpretabilidade para modelos de classificação\n",
        "\n",
        "\n",
        "Banco de dados:\n",
        "\n",
        "\n",
        "**Breast cancer wisconsin dataset**\n",
        "\n",
        "\n",
        "Disponível via sklearn\n",
        "\n",
        "\n",
        "> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.\n",
        ">\n",
        "> 1) ID number\n",
        ">\n",
        "> 2) Diagnosis (0 = malignant, 1 = benign)\n",
        ">\n",
        "> 3-32)\n",
        ">\n",
        "> Ten real-valued features are computed for each cell nucleus:\n",
        ">\n",
        "> a) radius (mean of distances from center to points on the perimeter)\n",
        ">\n",
        "> b) texture (standard deviation of gray-scale values)\n",
        ">\n",
        "> c) perimeter\n",
        ">\n",
        "> d) area\n",
        ">\n",
        "> e) smoothness (local variation in radius lengths)\n",
        ">\n",
        "> f) compactness (perimeter^2 / area - 1.0)\n",
        ">\n",
        "> g) concavity (severity of concave portions of the contour)\n",
        ">\n",
        "> h) concave points (number of concave portions of the contour)\n",
        ">\n",
        "> i) symmetry\n",
        ">\n",
        "> j) fractal dimension (\"coastline approximation\" - 1)"
      ],
      "metadata": {
        "id": "zxHUgPSFM1fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import das principais funções e leitura dos dados\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "w1NLIkJMRP4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "Wfg5H5k7QUoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.load_breast_cancer()"
      ],
      "metadata": {
        "id": "cz13V0q4Q5ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data.data, columns=data.feature_names)"
      ],
      "metadata": {
        "id": "39H8czgiIvdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = pd.DataFrame(data.target, columns=['Target'])\n",
        "df = pd.concat([df, target], axis=1)"
      ],
      "metadata": {
        "id": "do_VDG4RJICz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "gE2hH2_8SHHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "K94v4s0lSNC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "iyj0P08tSR5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "D4JMYa2ZJSto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treino de modelo de decision tree e interpretabilidade\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Para treinar um modelo de regressão utilizaremos o pacote sklearn.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Separação do banco entre treino e teste\n",
        "O primeiro passo para se treinar um modelo é separar o banco entre treino e teste. Para isso utilizaremos a função train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "``` python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n",
        "```\n",
        "No exemplo acima X é um dataframe contendo as features do modelo e Y um dataframe com a variável target.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "O parâmetro test_size controla o percentual de dados que será utilizado para teste.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "O parâmetro random_state controla a aleatoriedade da geração do dado, permitindo que ao reexecutar o código seja gerado os mesmos bancos de treino e teste.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "É importante separar o banco entre treino e teste, pois utilizaremos o banco de treino para treinar modelos e o banco de teste para avaliar os modelos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Treino do modelo\n",
        "Agora que já possuímos os dados de treino e teste vamos treinar o nosso modelo XGBoost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "``` python\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(objective='binary:logistic')\n",
        "model.fit(X_train, Y_train)\n",
        "```\n",
        "\n",
        "\n",
        "No código acima o objeto model é do tipo XGBClassifier, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado a árvore e a importância das features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "``` python\n",
        "# Para fazer predições de classes\n",
        "model.predict(X_test)\n",
        "# Para fazer predições de probabilidade\n",
        "model.predict_proba(X_test)\n",
        "# Para acessar a importância\n",
        "model.feature_importances_\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### Interpretabilidade\n",
        "Para trazer interpretabilidade em modelos do tipo árvore utilizamos o SHAP value(SHapley Additive exPlanations); Valores positivos são indicativos de impacto positivo da feature.\n",
        "\n",
        "\n",
        "O SHAP values é calculado sobre o banco de teste. Com base no impacto que a feature trouxe para cada observação podemos ter uma análise geral do impacto, uma análise correlacionando duas features e uma análise a nível individual.\n",
        "\n",
        "\n",
        "Observação SHAP é independente do tipo de modelo utilizado.\n",
        "\n",
        "\n",
        "```python\n",
        "#Criando o cálculo\n",
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "\n",
        "#Plot geral\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "\n",
        "#Plot relação\n",
        "shap.dependence_plot(var1, shap_values, X_test,interaction_index=var2)\n",
        "\n",
        "\n",
        "#Plot explicando uma observação\n",
        "shap_values = explainer(X_test)\n",
        "shap.waterfall_plot(shap_values[idx])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Exercício:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Separe o banco entre treino e teste. Use 30% do banco para teste. Faça a quebra com todas as variáveis.\n",
        "* Treine um modelo.\n",
        "* Faça análise do impacto das features no geral\n",
        "* Faça análise das features para a observação 2 do banco de teste."
      ],
      "metadata": {
        "id": "M9mSwwoqRbef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "Y = data.target"
      ],
      "metadata": {
        "id": "G4pgJuxgN_XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solução"
      ],
      "metadata": {
        "id": "idl1fuKB-1TJ"
      }
    }
  ]
}