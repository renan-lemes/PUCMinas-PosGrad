{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW9cxipaGvcf"
      },
      "source": [
        "# Classificador com multiplas classes\n",
        "---\n",
        "**Aula Prática 17**: Multiplas classes\n",
        "\n",
        "\n",
        "**Objetivo**: Treinar modelos para classificação não binaria\n",
        "\n",
        "\n",
        "Banco de dados:\n",
        "\n",
        "\n",
        "**MNIST**\n",
        "[Link](https://drive.google.com/file/d/1yQgW3xg8AKT4XmVnxHvGo5ldIzaYY0n3/view?usp=drive_link)\n",
        "\n",
        "Dado que representa a escrita de um número. Os labels são os números de 0 a 10, cada feature representa um pixel da figura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YvvVV47oGswH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8A43PxYxdlbN"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('mnist_train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAwIIqGlHO0b"
      },
      "source": [
        "## Treino de modelo\n",
        "---\n",
        "\n",
        "\n",
        "### Separação do banco entre treino e teste\n",
        "O primeiro passo para se treinar um modelo é separar o banco entre treino e teste. Para isso utilizaremos a função train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "``` python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n",
        "```\n",
        "No exemplo acima X é um dataframe contendo as features do modelo e Y um dataframe com a variável target.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "O parâmetro test_size controla o percentual de dados que será utilizado para teste.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "O parâmetro random_state controla a aleatoriedade da geração do dado, permitindo que ao reexecutar o código seja gerado os mesmos bancos de treino e teste.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "É importante separar o banco entre treino e teste, pois utilizaremos o banco de treino para treinar modelos e o banco de teste para avaliar os modelos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Treino do modelo\n",
        "Agora que já possuímos os dados de treino e teste vamos treinar os nossos modelos\n",
        "\n",
        "\n",
        "#### Regressão:\n",
        "``` python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(penalty='none')\n",
        "model.fit(X_train, Y_train)\n",
        "```\n",
        "\n",
        "\n",
        "No código acima o objeto model é do tipo LogisticRegression, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado nele os coeficientes do modelo.\n",
        "\n",
        "\n",
        "``` python\n",
        "# Para acessar os coeficientes\n",
        "model.coef_\n",
        "# Para acessar o intercepto\n",
        "model.intercept_\n",
        "# Para fazer predições de classes\n",
        "model.predict(X_test)\n",
        "# Para fazer predições de probabilidade\n",
        "model.predict_proba(X_test)\n",
        "```\n",
        "--------------------------------------------\n",
        "#### Random Forest:\n",
        "\n",
        "\n",
        "``` python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "```\n",
        "\n",
        "\n",
        "No código acima o objeto model é do tipo RandomForestClassifier, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado a árvore e a importancia das features.\n",
        "\n",
        "\n",
        "``` python\n",
        "# Para fazer predições de classes\n",
        "model.predict(X_test)\n",
        "# Para fazer predições de probabilidade\n",
        "model.predict_proba(X_test)\n",
        "# Para acessar a importancia\n",
        "model.feature_importances_\n",
        "```\n",
        "----------------------------\n",
        "#### XGBoost:\n",
        "``` python\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(objective='multi:softmax')\n",
        "model.fit(X_train, Y_train)\n",
        "```\n",
        "\n",
        "\n",
        "No código acima o objeto model é do tipo XGBClassifier, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado a árvore e a importância das features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "``` python\n",
        "# Para fazer predições de classes\n",
        "model.predict(X_test)\n",
        "# Para fazer predições de probabilidade\n",
        "model.predict_proba(X_test)\n",
        "# Para acessar a importancia\n",
        "model.feature_importances_\n",
        "```\n",
        "\n",
        "\n",
        "### Avaliação do modelo\n",
        "Para avaliar o modelo treinado utilizaremos as métricas vistas na aula teórica.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "``` python\n",
        "from sklearn.metrics import classification_report, confusion_matrix,\n",
        "\n",
        "\n",
        "# Métricas acurácia, precisão, recall, f1-score\n",
        "print(classification_report(Y_test, Y_predit))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Matriz de confusão\n",
        "confusion_matrix(Y_test, Y_predit)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Também é possível se obter cada uma das métricas do report\n",
        "``` python\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "recall_score(Y_test, Y_predict, pos_label=1)\n",
        "```\n",
        "\n",
        "\n",
        "--------------------\n",
        "### Exercício:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Separe o banco entre treino e teste. Use 30% do banco para teste. Faça a quebra com todas as variáveis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Treine um modelo utilizando regressão\n",
        "* Treine um modelo utilizando random forest (parâmetros default)\n",
        "* Treine um modelo utilizando xgboost (parâmetros default)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-srkXdnTsbV8"
      },
      "source": [
        "#### Solução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "##  importando as libs dos modelos\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "## importando as metricas\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>1x1</th>\n",
              "      <th>1x2</th>\n",
              "      <th>1x3</th>\n",
              "      <th>1x4</th>\n",
              "      <th>1x5</th>\n",
              "      <th>1x6</th>\n",
              "      <th>1x7</th>\n",
              "      <th>1x8</th>\n",
              "      <th>1x9</th>\n",
              "      <th>...</th>\n",
              "      <th>28x19</th>\n",
              "      <th>28x20</th>\n",
              "      <th>28x21</th>\n",
              "      <th>28x22</th>\n",
              "      <th>28x23</th>\n",
              "      <th>28x24</th>\n",
              "      <th>28x25</th>\n",
              "      <th>28x26</th>\n",
              "      <th>28x27</th>\n",
              "      <th>28x28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
              "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "\n",
              "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
              "0      0      0      0      0      0      0      0      0  \n",
              "1      0      0      0      0      0      0      0      0  \n",
              "2      0      0      0      0      0      0      0      0  \n",
              "3      0      0      0      0      0      0      0      0  \n",
              "4      0      0      0      0      0      0      0      0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[[\"label\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1 = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-6.32374549e-05,  5.22240244e-05,  4.81626437e-05, -6.68208807e-05,\n",
              "        2.43496362e-05,  3.84743908e-04, -3.40927873e-05,  1.30780673e-04,\n",
              "       -3.86126981e-04, -8.99827813e-05])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 2, 5, ..., 9, 1, 4], dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model_1.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_prob = model_1.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.82468902e-05, 2.05918140e-09, 1.91156823e-06, ...,\n",
              "        1.01179257e-06, 6.49603592e-05, 7.60446576e-05],\n",
              "       [6.20762079e-05, 6.50749363e-06, 9.25134892e-01, ...,\n",
              "        3.53026183e-11, 7.38411253e-02, 2.92192651e-07],\n",
              "       [1.00578662e-01, 6.29096410e-08, 1.52086401e-02, ...,\n",
              "        5.27578242e-07, 1.84014839e-01, 1.47016612e-03],\n",
              "       ...,\n",
              "       [1.18085515e-03, 1.04146878e-12, 5.45137201e-08, ...,\n",
              "        4.57590817e-01, 1.56067745e-05, 5.37866635e-01],\n",
              "       [6.40644702e-06, 9.80915812e-01, 3.03367672e-03, ...,\n",
              "        8.74448276e-09, 1.56252070e-02, 6.84355059e-06],\n",
              "       [1.51386406e-05, 1.54084826e-06, 2.51621262e-04, ...,\n",
              "        2.73176062e-04, 2.87537069e-04, 2.41120761e-02]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      1798\n",
            "           1       0.96      0.97      0.96      2024\n",
            "           2       0.92      0.89      0.91      1831\n",
            "           3       0.89      0.90      0.90      1820\n",
            "           4       0.93      0.93      0.93      1764\n",
            "           5       0.88      0.86      0.87      1591\n",
            "           6       0.94      0.96      0.95      1769\n",
            "           7       0.93      0.93      0.93      1845\n",
            "           8       0.89      0.87      0.88      1783\n",
            "           9       0.89      0.91      0.90      1775\n",
            "\n",
            "    accuracy                           0.92     18000\n",
            "   macro avg       0.92      0.92      0.92     18000\n",
            "weighted avg       0.92      0.92      0.92     18000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1739    0    5    4    3   18   12    5    9    3]\n",
            " [   0 1957   13    9    2    5    1    3   26    8]\n",
            " [   9   29 1634   40   21    7   21   17   43   10]\n",
            " [   4    5   30 1641    1   61    6   23   34   15]\n",
            " [   3    6    8    2 1641    7   18    8   16   55]\n",
            " [  20    5   27   59   14 1366   30    7   44   19]\n",
            " [  14    2   18    0   13   18 1697    1    5    1]\n",
            " [   4    4   17   13   17    2    2 1715    8   63]\n",
            " [  15   31   22   60    7   50   13    7 1557   21]\n",
            " [  12    3    3   19   51   14    1   51   11 1610]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_2 = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.07825715e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.51486305e-06, 1.53649995e-06,\n",
              "       6.44963889e-06, 1.07325627e-06, 2.48605451e-06, 9.94659160e-07,\n",
              "       9.91987072e-07, 3.41682040e-06, 2.45569255e-06, 2.98674834e-06,\n",
              "       4.21450551e-06, 1.88999881e-06, 9.38290094e-07, 2.64661456e-07,\n",
              "       5.07200278e-07, 1.88815102e-06, 7.42331057e-07, 4.27592269e-07,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 3.96969990e-07, 1.56493034e-06, 3.47245095e-06,\n",
              "       1.91724124e-05, 1.30751684e-05, 2.62860008e-05, 9.70900591e-05,\n",
              "       1.41381370e-04, 2.00049829e-04, 1.21144349e-04, 7.40923261e-05,\n",
              "       1.16653221e-04, 5.83867309e-05, 1.56488575e-04, 7.50488721e-05,\n",
              "       1.92459809e-05, 8.53579349e-06, 5.96697280e-06, 1.00820284e-06,\n",
              "       1.04307342e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.50626939e-06, 2.96761521e-06, 1.61933635e-05, 2.77475639e-05,\n",
              "       6.75217817e-05, 1.55874544e-04, 1.69775131e-04, 4.05126148e-04,\n",
              "       4.85260954e-04, 9.91438670e-04, 1.22402320e-03, 2.21002701e-03,\n",
              "       2.28827067e-03, 1.82373602e-03, 1.09141048e-03, 5.36162108e-04,\n",
              "       3.74401627e-04, 1.38688469e-04, 7.39936321e-05, 2.68608873e-05,\n",
              "       1.20114582e-05, 3.26986268e-06, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.50649752e-07,\n",
              "       2.38719129e-06, 1.26265971e-05, 3.50267024e-05, 8.21956603e-05,\n",
              "       1.68016190e-04, 3.51363260e-04, 7.39001464e-04, 8.33025061e-04,\n",
              "       1.74850789e-03, 2.34245803e-03, 1.87243362e-03, 1.92606159e-03,\n",
              "       1.33305478e-03, 1.47280877e-03, 8.32776104e-04, 7.19197524e-04,\n",
              "       4.14570313e-04, 2.32094185e-04, 1.45813736e-04, 9.49261279e-05,\n",
              "       3.54494873e-05, 2.01273744e-05, 4.07523075e-06, 5.17391894e-07,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.48444424e-06,\n",
              "       9.89444828e-06, 4.66847412e-05, 1.29660827e-04, 2.73692114e-04,\n",
              "       5.45962540e-04, 8.96252906e-04, 2.64090522e-03, 2.48967438e-03,\n",
              "       2.77455014e-03, 3.49818462e-03, 5.23189806e-03, 6.75793718e-03,\n",
              "       6.44098777e-03, 3.00219987e-03, 2.42411506e-03, 1.36791428e-03,\n",
              "       1.11861677e-03, 1.18413729e-03, 5.44341671e-04, 2.60293164e-04,\n",
              "       1.60233165e-04, 2.88383795e-05, 9.43864659e-06, 1.53090450e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.08891733e-06, 6.30004312e-06,\n",
              "       3.10307408e-05, 8.06126207e-05, 2.60833151e-04, 4.77262254e-04,\n",
              "       1.00030176e-03, 1.96042312e-03, 2.44567117e-03, 2.88563824e-03,\n",
              "       2.66867493e-03, 3.30355221e-03, 5.34032603e-03, 4.74696735e-03,\n",
              "       3.04377073e-03, 2.84804449e-03, 1.71469516e-03, 2.01826282e-03,\n",
              "       1.37702443e-03, 1.06412784e-03, 8.16358661e-04, 7.80046680e-04,\n",
              "       2.83408144e-04, 6.18362427e-05, 1.17545805e-05, 3.20351248e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 7.37166221e-07, 1.03438359e-05,\n",
              "       7.21593630e-05, 1.54318957e-04, 2.86801564e-04, 5.70858103e-04,\n",
              "       1.28989128e-03, 1.38129208e-03, 2.82828557e-03, 2.33892120e-03,\n",
              "       3.01130060e-03, 3.12433328e-03, 5.95447584e-03, 6.29316162e-03,\n",
              "       5.26871046e-03, 2.94731046e-03, 2.49360890e-03, 2.15789668e-03,\n",
              "       1.69186323e-03, 1.39516360e-03, 1.44035759e-03, 1.24223573e-03,\n",
              "       1.05899669e-03, 1.68966242e-04, 1.58625845e-05, 2.57007320e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.84337826e-06, 2.99821770e-05,\n",
              "       8.18492144e-05, 2.13071473e-04, 3.79047077e-04, 7.17636375e-04,\n",
              "       1.11507574e-03, 1.41488258e-03, 3.03214524e-03, 3.46045641e-03,\n",
              "       3.46864527e-03, 4.52514771e-03, 5.19418162e-03, 5.60518978e-03,\n",
              "       3.36641388e-03, 3.97992453e-03, 3.82546949e-03, 3.40434869e-03,\n",
              "       2.63672108e-03, 1.68554780e-03, 1.31358454e-03, 1.16042819e-03,\n",
              "       6.93253994e-04, 2.35085157e-04, 2.15388784e-05, 2.02687654e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.53543994e-06, 2.73484716e-05,\n",
              "       9.96334122e-05, 1.79918142e-04, 4.35913891e-04, 7.17588365e-04,\n",
              "       1.27793257e-03, 2.10442884e-03, 4.27734517e-03, 3.80913180e-03,\n",
              "       3.20968741e-03, 3.43806762e-03, 4.10526722e-03, 4.32235286e-03,\n",
              "       3.39862559e-03, 3.34954405e-03, 3.62215927e-03, 3.07535386e-03,\n",
              "       2.36038583e-03, 2.01631816e-03, 1.02194089e-03, 6.59351757e-04,\n",
              "       4.49626689e-04, 1.14488187e-04, 2.54536724e-05, 4.61609164e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.72016232e-06, 2.92902354e-05,\n",
              "       8.20982750e-05, 2.48528356e-04, 4.16534773e-04, 6.13702815e-04,\n",
              "       1.74353577e-03, 2.86396663e-03, 5.40554820e-03, 5.52433806e-03,\n",
              "       3.07412243e-03, 2.92015321e-03, 3.57349018e-03, 3.56302469e-03,\n",
              "       3.75051523e-03, 4.11644761e-03, 4.14858186e-03, 2.96991047e-03,\n",
              "       3.62195291e-03, 1.99984987e-03, 8.06720749e-04, 4.57027170e-04,\n",
              "       2.57146634e-04, 6.31500338e-05, 8.64538210e-06, 0.00000000e+00,\n",
              "       0.00000000e+00, 5.13302836e-07, 8.06771154e-06, 2.74083573e-05,\n",
              "       8.58251386e-05, 2.44762515e-04, 5.80604187e-04, 1.81498041e-03,\n",
              "       2.19525773e-03, 3.62801315e-03, 4.76034452e-03, 6.13212463e-03,\n",
              "       3.55732103e-03, 3.39711454e-03, 5.00325199e-03, 4.94784542e-03,\n",
              "       3.55166811e-03, 3.48438856e-03, 4.14586090e-03, 3.56425820e-03,\n",
              "       2.48244001e-03, 1.84104970e-03, 1.86327067e-03, 4.61730845e-04,\n",
              "       1.65410419e-04, 2.96349957e-05, 9.75972559e-06, 2.46255764e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.75062539e-06, 2.24796564e-05,\n",
              "       8.66185028e-05, 2.99983817e-04, 9.25403312e-04, 1.66970709e-03,\n",
              "       2.34073475e-03, 3.80922121e-03, 5.68613917e-03, 7.45842175e-03,\n",
              "       3.31048181e-03, 4.67023978e-03, 7.08368301e-03, 4.20330836e-03,\n",
              "       4.13137761e-03, 4.46859974e-03, 3.75989071e-03, 2.41882371e-03,\n",
              "       1.79202099e-03, 2.41416935e-03, 2.03471652e-03, 5.77040370e-04,\n",
              "       1.52638936e-04, 3.00998557e-05, 1.29362967e-05, 1.42841978e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.12890364e-06, 1.55497049e-05,\n",
              "       9.52564148e-05, 2.82399644e-04, 1.00856489e-03, 2.13055544e-03,\n",
              "       2.81442733e-03, 5.30666029e-03, 6.86916967e-03, 5.71533525e-03,\n",
              "       4.87521484e-03, 7.12242837e-03, 7.81692348e-03, 5.05442315e-03,\n",
              "       5.35189485e-03, 4.43223645e-03, 3.56333947e-03, 1.62988732e-03,\n",
              "       1.40910013e-03, 2.79581204e-03, 2.35383799e-03, 7.64442140e-04,\n",
              "       1.57255112e-04, 2.06197311e-05, 8.28105496e-06, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.02507372e-06, 1.23218702e-05,\n",
              "       1.14042912e-04, 3.23291161e-04, 7.94608959e-04, 2.32205141e-03,\n",
              "       3.67089528e-03, 4.28263999e-03, 5.27208629e-03, 5.23120647e-03,\n",
              "       3.45117187e-03, 7.62620672e-03, 8.50245216e-03, 3.60125491e-03,\n",
              "       4.31095265e-03, 7.10553867e-03, 4.04607103e-03, 1.58963388e-03,\n",
              "       1.24461921e-03, 1.12364323e-03, 1.48600734e-03, 5.93633609e-04,\n",
              "       1.68584115e-04, 3.00568167e-05, 1.07399054e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.88820887e-06, 1.83363862e-05,\n",
              "       1.03756666e-04, 5.34461040e-04, 1.00134936e-03, 3.59910297e-03,\n",
              "       4.54333566e-03, 4.66836393e-03, 4.68041318e-03, 3.92886541e-03,\n",
              "       4.40643733e-03, 8.15690597e-03, 5.78314509e-03, 3.49249523e-03,\n",
              "       3.96503066e-03, 8.52690603e-03, 2.30290242e-03, 2.11217272e-03,\n",
              "       1.25686029e-03, 1.63700400e-03, 7.03991012e-04, 7.65286774e-04,\n",
              "       1.67654100e-04, 4.55868264e-05, 9.55152663e-06, 1.76002261e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.91153020e-06, 3.50176772e-05,\n",
              "       9.68648138e-05, 3.65032334e-04, 1.11535521e-03, 4.06052536e-03,\n",
              "       3.57031475e-03, 4.69381934e-03, 4.50116888e-03, 3.52514755e-03,\n",
              "       6.84408584e-03, 6.67891143e-03, 4.94658542e-03, 3.02207519e-03,\n",
              "       2.52622475e-03, 4.04968238e-03, 2.80384856e-03, 1.94702887e-03,\n",
              "       1.04640655e-03, 1.20594104e-03, 7.89479091e-04, 4.04893660e-04,\n",
              "       1.63431939e-04, 4.15529022e-05, 1.95898729e-05, 9.26266097e-07,\n",
              "       0.00000000e+00, 2.41576764e-06, 3.32834497e-06, 4.01307623e-05,\n",
              "       1.19485125e-04, 4.69963297e-04, 1.33756196e-03, 3.09468906e-03,\n",
              "       3.30528064e-03, 3.65606470e-03, 4.86063413e-03, 5.72317998e-03,\n",
              "       5.26671219e-03, 4.70713897e-03, 5.21749038e-03, 3.08400104e-03,\n",
              "       1.79794485e-03, 1.88079797e-03, 1.95267665e-03, 1.47333726e-03,\n",
              "       1.41640433e-03, 8.72609574e-04, 6.38559501e-04, 4.35524456e-04,\n",
              "       2.09378601e-04, 6.96683122e-05, 1.92989885e-05, 6.17438446e-07,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.27736687e-05, 8.09491115e-05,\n",
              "       1.83416629e-04, 4.62673072e-04, 1.77416965e-03, 2.87329125e-03,\n",
              "       2.92208363e-03, 4.29514294e-03, 6.31718445e-03, 6.39226471e-03,\n",
              "       4.67582162e-03, 4.10875199e-03, 2.65825232e-03, 1.71359715e-03,\n",
              "       1.35696278e-03, 1.91809168e-03, 2.01043707e-03, 2.27268008e-03,\n",
              "       1.26174680e-03, 7.74383682e-04, 6.40859281e-04, 4.31107632e-04,\n",
              "       1.72045763e-04, 1.07438427e-04, 3.34245104e-06, 3.25130883e-06,\n",
              "       0.00000000e+00, 1.29968465e-06, 8.89866286e-06, 8.01159876e-05,\n",
              "       2.05724578e-04, 5.70750661e-04, 1.50598196e-03, 2.85484140e-03,\n",
              "       3.90070544e-03, 5.82328148e-03, 5.58746935e-03, 6.54232285e-03,\n",
              "       3.24254505e-03, 2.79585597e-03, 2.03894006e-03, 1.42381774e-03,\n",
              "       1.28008387e-03, 2.30584108e-03, 2.78869985e-03, 2.65952303e-03,\n",
              "       1.84073655e-03, 1.28453314e-03, 6.34905331e-04, 4.18499121e-04,\n",
              "       1.70084331e-04, 3.96701037e-05, 1.18205234e-06, 5.06454946e-07,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.95922977e-06, 7.54830024e-05,\n",
              "       2.03662222e-04, 4.71344123e-04, 1.88797809e-03, 5.10638814e-03,\n",
              "       2.89646544e-03, 5.83672352e-03, 3.83478473e-03, 3.76802847e-03,\n",
              "       3.27195336e-03, 1.93442415e-03, 1.95319558e-03, 1.67435026e-03,\n",
              "       1.34149506e-03, 1.59741952e-03, 2.92803384e-03, 1.99160312e-03,\n",
              "       1.13934100e-03, 1.01403300e-03, 6.61946889e-04, 4.15893736e-04,\n",
              "       9.91974924e-05, 3.02416374e-05, 5.68322778e-06, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.76262814e-06, 7.48960691e-05,\n",
              "       2.13622955e-04, 3.60748173e-04, 1.13603090e-03, 2.11497578e-03,\n",
              "       4.77639545e-03, 4.11551845e-03, 2.62501943e-03, 1.95754807e-03,\n",
              "       1.70248942e-03, 1.83615930e-03, 1.27167785e-03, 1.29079193e-03,\n",
              "       1.21750277e-03, 1.09533431e-03, 1.13548123e-03, 1.06579449e-03,\n",
              "       1.03062682e-03, 7.16570023e-04, 2.71719554e-04, 2.52687126e-04,\n",
              "       8.90087215e-05, 7.93304033e-06, 2.86662830e-06, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.02233333e-06, 2.31102741e-05,\n",
              "       1.38017262e-04, 3.23917217e-04, 8.87439179e-04, 1.11797780e-03,\n",
              "       2.52755919e-03, 5.10410966e-03, 2.23056914e-03, 2.40645976e-03,\n",
              "       1.78917039e-03, 1.57002234e-03, 1.74086833e-03, 1.39414783e-03,\n",
              "       1.24354414e-03, 1.08817622e-03, 1.09689865e-03, 5.52686521e-04,\n",
              "       3.81744988e-04, 2.68891644e-04, 1.68760715e-04, 7.19163752e-05,\n",
              "       2.67667002e-05, 5.02275862e-06, 5.23433565e-07, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.05496616e-06, 1.30446809e-05,\n",
              "       5.55956090e-05, 1.25970096e-04, 3.63488392e-04, 6.03948379e-04,\n",
              "       1.10311961e-03, 2.88430494e-03, 3.82848352e-03, 4.54837772e-03,\n",
              "       5.07428504e-03, 4.13506122e-03, 3.28265350e-03, 2.86938173e-03,\n",
              "       1.36092310e-03, 1.02958734e-03, 7.05889056e-04, 3.54878149e-04,\n",
              "       2.05267155e-04, 1.51255233e-04, 9.09119638e-05, 3.22560951e-05,\n",
              "       2.08302403e-05, 4.27114372e-06, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.27931025e-07, 9.10974384e-06,\n",
              "       3.69986541e-05, 9.19450070e-05, 2.24941925e-04, 3.59836610e-04,\n",
              "       6.77039359e-04, 8.10539940e-04, 1.10736062e-03, 1.59119575e-03,\n",
              "       1.72496133e-03, 1.76811944e-03, 8.20952299e-04, 7.04483738e-04,\n",
              "       5.39866989e-04, 4.61458278e-04, 3.74829607e-04, 2.85317904e-04,\n",
              "       1.53966862e-04, 9.07265774e-05, 4.94868110e-05, 1.32775436e-05,\n",
              "       9.17202675e-06, 9.97988549e-07, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.28130520e-06,\n",
              "       7.09292628e-06, 4.74779692e-05, 7.82010419e-05, 3.05606798e-04,\n",
              "       6.48436901e-04, 6.50475563e-04, 1.02345516e-03, 1.13034719e-03,\n",
              "       9.69376408e-04, 6.51762997e-04, 5.99968173e-04, 4.75244593e-04,\n",
              "       4.54450101e-04, 4.10251744e-04, 2.64334978e-04, 2.08908790e-04,\n",
              "       8.55976304e-05, 2.96714853e-05, 1.06081549e-05, 6.75494526e-06,\n",
              "       9.49457605e-07, 0.00000000e+00, 9.58479198e-07, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.29320995e-07,\n",
              "       4.20060473e-06, 8.73749718e-06, 1.21578728e-05, 2.78498899e-05,\n",
              "       4.36404641e-05, 9.17463168e-05, 1.18616272e-04, 1.54201091e-04,\n",
              "       4.00402329e-04, 1.68239592e-04, 1.19644447e-04, 1.26792436e-04,\n",
              "       1.73462417e-04, 1.10224255e-04, 5.04406535e-05, 4.38486344e-05,\n",
              "       2.41078925e-05, 1.45822089e-05, 6.77693839e-06, 4.76603803e-07,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.63123530e-07,\n",
              "       2.02333592e-06, 0.00000000e+00, 5.06639339e-06, 5.94339128e-06,\n",
              "       1.48741348e-06, 5.04489059e-06, 1.35074015e-05, 9.50446057e-06,\n",
              "       6.50385431e-06, 6.21714845e-06, 8.93138575e-07, 5.20395194e-07,\n",
              "       8.73354295e-07, 1.56389719e-06, 4.18907768e-06, 2.06262522e-06,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 2, 5, ..., 7, 1, 4], dtype=int64)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model_2.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.02, 0.01, 0.01, ..., 0.03, 0.  , 0.05],\n",
              "       [0.  , 0.  , 0.84, ..., 0.02, 0.06, 0.01],\n",
              "       [0.03, 0.  , 0.06, ..., 0.03, 0.05, 0.13],\n",
              "       ...,\n",
              "       [0.  , 0.  , 0.  , ..., 0.86, 0.  , 0.08],\n",
              "       [0.  , 0.96, 0.  , ..., 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.  , ..., 0.06, 0.02, 0.04]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob = model_2.predict_proba(X_test)\n",
        "y_pred_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      1798\n",
            "           1       0.99      0.98      0.99      2024\n",
            "           2       0.96      0.97      0.96      1831\n",
            "           3       0.96      0.95      0.96      1820\n",
            "           4       0.97      0.98      0.97      1764\n",
            "           5       0.96      0.96      0.96      1591\n",
            "           6       0.98      0.98      0.98      1769\n",
            "           7       0.98      0.96      0.97      1845\n",
            "           8       0.96      0.96      0.96      1783\n",
            "           9       0.96      0.95      0.96      1775\n",
            "\n",
            "    accuracy                           0.97     18000\n",
            "   macro avg       0.97      0.97      0.97     18000\n",
            "weighted avg       0.97      0.97      0.97     18000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1779    0    3    1    1    1    4    0    9    0]\n",
            " [   0 1992   10    4    2    2    3    2    5    4]\n",
            " [   7    6 1771    7   12    1   10    8    7    2]\n",
            " [   2    2   18 1732    0   19    2   15   19   11]\n",
            " [   2    2    3    0 1725    0    5    1    6   20]\n",
            " [   8    1    4   19    3 1530    9    0   11    6]\n",
            " [   7    2    1    0    2   13 1739    0    5    0]\n",
            " [   2    6   20    2   11    1    0 1779    5   19]\n",
            " [   7    7   10   14    7   17    3    3 1705   10]\n",
            " [  12    2    4   19   21    6    1   12   10 1688]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3 = XGBClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, objective='multi:softprob', ...)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.27985380e-04, 0.00000000e+00, 8.49144300e-04,\n",
              "       7.20862517e-05, 3.70923604e-04, 4.80302796e-03, 1.72303966e-03,\n",
              "       3.01575928e-04, 1.43284095e-04, 3.43335851e-04, 1.18722361e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.84996320e-04,\n",
              "       5.84303821e-03, 2.42198212e-03, 4.52198274e-02, 2.78026634e-03,\n",
              "       6.43154187e-03, 3.10057811e-02, 5.31089841e-04, 6.01361739e-03,\n",
              "       7.40400632e-04, 6.72762394e-02, 2.55589635e-04, 3.35495220e-04,\n",
              "       1.65253151e-02, 1.66664855e-03, 2.08344241e-03, 2.25354382e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.58506446e-04, 2.21181093e-04,\n",
              "       9.50030808e-05, 2.25064388e-04, 4.15145099e-04, 2.58516520e-04,\n",
              "       3.58657446e-03, 4.41232638e-04, 2.29288475e-03, 4.28111147e-04,\n",
              "       8.76774837e-04, 2.71902885e-04, 3.86456551e-04, 5.12178289e-04,\n",
              "       3.42842337e-04, 4.44927282e-04, 6.43332954e-04, 1.71107764e-04,\n",
              "       1.11894049e-04, 3.39674531e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.16039919e-04,\n",
              "       0.00000000e+00, 1.27302264e-04, 2.59450317e-04, 2.20060043e-04,\n",
              "       5.91807766e-04, 4.46942897e-04, 7.74265826e-03, 4.26289975e-04,\n",
              "       3.81827325e-04, 1.18612067e-03, 9.53215931e-04, 8.81637167e-03,\n",
              "       3.69227491e-03, 2.09926598e-04, 1.22074026e-03, 4.39391355e-04,\n",
              "       2.28297067e-04, 6.09268958e-04, 1.96600246e-04, 5.33955963e-03,\n",
              "       1.81377560e-04, 5.14862593e-04, 3.03125009e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.09403991e-04,\n",
              "       0.00000000e+00, 9.05659050e-04, 1.60275522e-04, 3.57013399e-04,\n",
              "       1.25361420e-03, 8.70925374e-04, 1.45415950e-03, 9.29506088e-04,\n",
              "       1.27102004e-03, 2.59048742e-04, 9.11224459e-04, 3.91063164e-04,\n",
              "       3.75264150e-04, 9.97912139e-04, 3.17880942e-04, 2.31468162e-04,\n",
              "       2.89961579e-04, 2.04326678e-03, 2.00168369e-03, 6.81315083e-04,\n",
              "       1.30351764e-04, 2.44396331e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       6.01395965e-04, 4.07371292e-04, 4.38217830e-04, 5.63322741e-04,\n",
              "       5.43824688e-04, 1.40857790e-03, 2.38489965e-03, 3.47590918e-04,\n",
              "       1.11423573e-03, 3.70259222e-04, 2.05019978e-03, 7.96357263e-03,\n",
              "       6.50858390e-04, 2.84482236e-03, 3.75706644e-04, 1.07523706e-03,\n",
              "       1.09099259e-03, 7.80337083e-04, 6.54936593e-04, 7.24927289e-03,\n",
              "       1.26636298e-02, 2.83892645e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.93927966e-04, 2.15533597e-04, 2.31378106e-03, 1.18248758e-03,\n",
              "       8.34308914e-04, 1.15585036e-03, 3.11600365e-04, 5.85329160e-03,\n",
              "       4.22601530e-04, 4.97662753e-04, 2.54333805e-04, 3.92594200e-04,\n",
              "       3.67880653e-04, 3.39755934e-04, 2.08888436e-03, 4.08363482e-03,\n",
              "       2.33872153e-04, 1.40228239e-03, 4.70190163e-04, 1.96694466e-03,\n",
              "       2.93250137e-04, 2.17258217e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.04895525e-03,\n",
              "       4.29323292e-04, 2.47666292e-04, 6.57778466e-04, 1.28070504e-04,\n",
              "       2.44801340e-04, 4.71492036e-04, 1.09102880e-03, 5.08747762e-04,\n",
              "       3.19680054e-04, 3.40430881e-04, 4.70351486e-04, 1.95253920e-03,\n",
              "       8.24916759e-04, 6.12694595e-04, 3.15580890e-03, 9.11430514e-04,\n",
              "       1.05568697e-03, 1.16865570e-03, 2.64083501e-04, 5.81816304e-04,\n",
              "       7.00974744e-03, 1.51047701e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.88453084e-04, 2.95666716e-04, 2.21863971e-04, 4.68770275e-04,\n",
              "       5.91085176e-04, 4.03158553e-03, 2.78132153e-03, 8.37539672e-04,\n",
              "       3.64001287e-04, 6.83361723e-04, 2.38283933e-03, 1.37776439e-03,\n",
              "       1.59544148e-03, 5.06037904e-04, 1.21445232e-03, 7.74838496e-04,\n",
              "       2.97035417e-03, 1.41627458e-03, 9.19635699e-04, 4.70442756e-04,\n",
              "       7.00124947e-04, 3.33102653e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       6.72672351e-04, 1.12510301e-04, 4.90492268e-04, 8.38607142e-04,\n",
              "       1.38797949e-03, 1.02081860e-03, 1.54530001e-03, 1.23746402e-03,\n",
              "       9.49875102e-04, 1.00094255e-03, 7.60861789e-04, 3.85885971e-04,\n",
              "       8.63661291e-04, 6.57621247e-04, 2.17499747e-03, 8.51284480e-04,\n",
              "       3.34321451e-03, 5.38838003e-03, 5.59290464e-04, 6.72644179e-04,\n",
              "       4.07526502e-04, 1.33170886e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.99427275e-04,\n",
              "       4.81293333e-04, 3.78012104e-04, 5.44165261e-04, 6.14550011e-03,\n",
              "       7.15494913e-04, 1.35648996e-03, 8.02203733e-03, 1.49237900e-03,\n",
              "       3.53390351e-04, 3.27816722e-03, 3.16831167e-03, 1.06075231e-03,\n",
              "       2.12894447e-04, 1.53934187e-03, 9.50477086e-04, 2.89269956e-03,\n",
              "       4.14466602e-04, 9.22079198e-04, 1.45732434e-02, 1.72932388e-03,\n",
              "       3.53337731e-04, 2.12924730e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.99530302e-04,\n",
              "       3.74541356e-04, 5.51087607e-04, 1.32687890e-03, 1.88854686e-03,\n",
              "       6.41997205e-04, 4.80666116e-04, 1.00734562e-03, 5.53231162e-04,\n",
              "       1.27369654e-03, 1.55062589e-03, 9.78802796e-04, 6.71181944e-04,\n",
              "       7.69553357e-04, 1.59944838e-03, 6.36222539e-04, 2.87792674e-04,\n",
              "       3.16245481e-04, 2.93735589e-04, 2.39137048e-03, 4.63021686e-04,\n",
              "       5.22507005e-04, 2.95597332e-04, 2.65907234e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.41787905e-04,\n",
              "       2.88914831e-04, 3.11164535e-04, 5.49828750e-04, 7.01942074e-04,\n",
              "       4.01254930e-03, 1.05916115e-03, 8.23949405e-04, 9.04010783e-04,\n",
              "       4.08563996e-03, 9.47346352e-03, 6.02796394e-03, 9.76664107e-03,\n",
              "       8.34012055e-04, 1.05800934e-03, 4.41811699e-03, 5.24733856e-04,\n",
              "       2.58117710e-04, 2.23742740e-04, 5.05213742e-04, 3.53468291e-04,\n",
              "       4.10334003e-04, 5.53718070e-04, 9.52705523e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.56908039e-04,\n",
              "       3.58893478e-04, 4.58028750e-04, 9.74278431e-04, 8.51562305e-04,\n",
              "       8.65844835e-04, 1.85477408e-03, 6.19617116e-04, 1.94905011e-03,\n",
              "       1.98109727e-03, 9.65099025e-04, 1.48293306e-03, 4.92428010e-03,\n",
              "       3.28997266e-04, 1.00343265e-02, 4.10392461e-03, 4.91412939e-04,\n",
              "       3.36746511e-04, 4.21726581e-04, 7.83036405e-04, 6.63870305e-04,\n",
              "       4.55531612e-04, 4.09379747e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.76592798e-05,\n",
              "       4.21932462e-04, 1.77795626e-03, 2.67740601e-04, 2.46027764e-03,\n",
              "       6.31752191e-04, 1.89200626e-03, 1.29289425e-03, 7.62530719e-04,\n",
              "       1.19939505e-03, 8.98019003e-04, 1.87399611e-03, 8.46215407e-04,\n",
              "       7.03401747e-04, 2.10804574e-04, 1.36260409e-03, 5.58373751e-04,\n",
              "       4.63613920e-04, 3.22953274e-04, 1.89767184e-03, 6.26747031e-04,\n",
              "       2.61673704e-04, 2.35606311e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.23669247e-04,\n",
              "       4.86716541e-04, 2.99915439e-04, 4.07798769e-04, 3.29929171e-04,\n",
              "       5.57329156e-04, 8.10430385e-04, 2.02971394e-03, 4.19976702e-03,\n",
              "       4.34651796e-04, 4.70460067e-03, 3.01408907e-03, 3.12518881e-04,\n",
              "       2.04836775e-04, 4.49969550e-04, 1.46176331e-04, 3.38745071e-04,\n",
              "       1.24146207e-03, 4.31715132e-04, 3.52455652e-04, 2.07251127e-04,\n",
              "       1.94526732e-03, 8.59045016e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.82215891e-04, 6.85253879e-04,\n",
              "       3.89136869e-04, 2.18818284e-04, 1.02883112e-03, 1.71555916e-03,\n",
              "       2.23955233e-03, 3.57174053e-04, 5.44004515e-03, 2.10293056e-03,\n",
              "       1.37703645e-03, 3.09499539e-03, 9.01038817e-04, 5.00100025e-04,\n",
              "       2.96864775e-04, 6.53191702e-04, 1.01668935e-03, 9.02395521e-04,\n",
              "       3.36254510e-04, 4.94286825e-04, 1.81115547e-03, 4.18289361e-04,\n",
              "       7.20711146e-03, 6.21277140e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.78178845e-04,\n",
              "       1.41611893e-03, 4.32291796e-04, 1.10378675e-03, 4.96324152e-03,\n",
              "       3.39557347e-03, 3.18770326e-04, 4.41693235e-03, 2.16048490e-03,\n",
              "       1.35254906e-03, 6.69256144e-04, 3.45341599e-04, 1.76692527e-04,\n",
              "       3.37623002e-04, 3.62915482e-04, 3.81206907e-03, 7.82752293e-04,\n",
              "       4.54755849e-04, 5.20633941e-04, 8.04752926e-04, 8.19925976e-04,\n",
              "       3.40846297e-03, 1.00457913e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.15209890e-02,\n",
              "       1.93856116e-02, 5.47346368e-04, 2.10986982e-04, 2.34539015e-03,\n",
              "       9.74967494e-04, 7.48353964e-03, 4.50799428e-03, 6.61909464e-04,\n",
              "       3.61668994e-04, 3.01205757e-04, 6.40594983e-04, 2.06592566e-04,\n",
              "       1.89965052e-04, 2.30149075e-04, 3.49585112e-04, 6.52864226e-04,\n",
              "       3.55941156e-04, 2.78752064e-03, 3.52701114e-04, 2.41241287e-02,\n",
              "       2.12947401e-04, 1.13933405e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.05709905e-04, 2.54525075e-04, 1.69621815e-03, 5.71735960e-04,\n",
              "       5.90170966e-04, 2.35423609e-03, 1.54242013e-03, 1.69761392e-04,\n",
              "       1.81723840e-03, 2.13360938e-04, 3.10940610e-04, 3.06787115e-04,\n",
              "       2.35095009e-04, 1.82631440e-04, 3.44157306e-04, 5.56104700e-04,\n",
              "       3.80638929e-04, 3.37780308e-04, 8.87928298e-04, 1.60575408e-04,\n",
              "       2.18408852e-04, 1.22414611e-04, 1.05998501e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22080373e-04,\n",
              "       3.61223472e-04, 3.29426781e-04, 9.27832152e-04, 1.00427901e-03,\n",
              "       7.88587960e-04, 8.71630444e-04, 7.40538002e-04, 6.91005029e-04,\n",
              "       3.41533974e-04, 4.65108344e-04, 2.09157923e-04, 1.63155783e-04,\n",
              "       2.24352931e-04, 2.17286608e-04, 2.96786369e-04, 6.37946767e-04,\n",
              "       1.64477722e-04, 1.17572839e-03, 1.67963305e-03, 1.92596111e-04,\n",
              "       1.51919230e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.95331192e-04,\n",
              "       4.54255467e-04, 1.69627659e-04, 1.55979345e-04, 7.77780893e-04,\n",
              "       4.75887471e-04, 9.57591110e-04, 1.12550892e-03, 8.66227318e-04,\n",
              "       5.59418555e-03, 6.04190351e-03, 6.46275352e-04, 1.69870537e-03,\n",
              "       8.50824756e-04, 5.79524087e-04, 1.00001786e-03, 5.56965766e-04,\n",
              "       2.21906928e-04, 2.33980449e-04, 1.14653907e-04, 5.76130289e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.54306016e-04,\n",
              "       2.10597273e-03, 4.64427809e-04, 3.21157975e-04, 2.69974931e-04,\n",
              "       2.98886473e-04, 2.75755330e-04, 8.88968061e-04, 5.62805450e-04,\n",
              "       6.10533520e-04, 1.51468092e-03, 3.26097390e-04, 2.11216262e-04,\n",
              "       1.00944145e-03, 3.17708560e-04, 7.83184019e-04, 6.14570570e-04,\n",
              "       3.12937453e-04, 3.58590944e-04, 3.17185099e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.21209901e-04, 8.18235613e-03, 3.82585707e-03,\n",
              "       1.65913522e-03, 1.15591856e-02, 4.97253705e-03, 7.30477972e-04,\n",
              "       6.97892217e-04, 1.62135232e-02, 8.25023686e-04, 2.29639211e-03,\n",
              "       7.19899719e-04, 1.58174131e-02, 2.63410417e-04, 1.07646838e-03,\n",
              "       1.55813685e-02, 2.75024417e-04, 4.92538849e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.17365395e-04, 1.35494556e-04, 0.00000000e+00,\n",
              "       1.52550725e-04, 1.94264096e-04, 1.92616208e-04, 1.88096339e-04,\n",
              "       4.78046052e-02, 2.45745038e-03, 7.17375311e-04, 2.36624926e-02,\n",
              "       2.87050207e-04, 3.79280141e-03, 5.29185112e-04, 2.93354766e-04,\n",
              "       5.69539203e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 2, 5, ..., 7, 1, 4], dtype=int64)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model_3.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.61987429e-06, 4.23706842e-06, 1.75320729e-05, ...,\n",
              "        4.56399212e-05, 6.75433193e-06, 2.16388180e-05],\n",
              "       [6.67066161e-07, 9.19806735e-06, 9.99889731e-01, ...,\n",
              "        8.76169850e-07, 3.77640754e-05, 1.74281092e-06],\n",
              "       [1.08879185e-05, 2.41553380e-06, 8.65560742e-06, ...,\n",
              "        4.17430101e-06, 1.53532339e-04, 2.79800533e-05],\n",
              "       ...,\n",
              "       [4.58406721e-05, 1.01237777e-06, 2.07398216e-06, ...,\n",
              "        9.98443425e-01, 7.61011165e-07, 1.35528820e-03],\n",
              "       [4.33027452e-07, 9.99931455e-01, 1.00817997e-05, ...,\n",
              "        9.47008903e-06, 3.11724034e-05, 9.10512881e-07],\n",
              "       [6.84153747e-07, 1.04627475e-06, 7.52093820e-06, ...,\n",
              "        7.56356021e-05, 6.83830513e-06, 3.22832668e-04]], dtype=float32)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob = model_3.predict_proba(X_test)\n",
        "y_pred_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99      1798\n",
            "           1       0.99      0.98      0.99      2024\n",
            "           2       0.97      0.97      0.97      1831\n",
            "           3       0.98      0.96      0.97      1820\n",
            "           4       0.97      0.98      0.97      1764\n",
            "           5       0.97      0.97      0.97      1591\n",
            "           6       0.98      0.98      0.98      1769\n",
            "           7       0.98      0.98      0.98      1845\n",
            "           8       0.97      0.97      0.97      1783\n",
            "           9       0.96      0.97      0.96      1775\n",
            "\n",
            "    accuracy                           0.98     18000\n",
            "   macro avg       0.98      0.98      0.98     18000\n",
            "weighted avg       0.98      0.98      0.98     18000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1775    0    2    3    2    1    5    1    8    1]\n",
            " [   0 1992   10    5    1    3    1    3    6    3]\n",
            " [   2    6 1782   12    7    0    4   13    4    1]\n",
            " [   1    1   13 1756    3   13    1    7   14   11]\n",
            " [   0    2    3    0 1731    0    2    0    5   21]\n",
            " [   7    2    2    7    3 1547   12    0    5    6]\n",
            " [   5    2    0    1    3   11 1740    0    6    1]\n",
            " [   2    1   10    1    7    0    0 1806    4   14]\n",
            " [   7    5    5    8    7    7    5    3 1731    5]\n",
            " [   6    2    1    5   26    9    0    9    4 1713]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
