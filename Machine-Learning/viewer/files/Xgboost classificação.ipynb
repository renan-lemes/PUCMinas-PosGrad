{"cells":[{"cell_type":"markdown","metadata":{"id":"zxHUgPSFM1fc"},"source":["#XGBoost\n","---\n","**Aula Prática 09**: XGBoost para classificação\n","\n","\n","**Objetivo**: Treinar modelo de classificação\n","\n","\n","Banco de dados:\n","\n","\n","**Breast cancer wisconsin dataset**\n","\n","\n","Disponível via sklearn\n","\n","\n","> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.\n",">\n","> 1) ID number\n",">\n","> 2) Diagnosis (0 = malignant, 1 = benign)\n",">\n","> 3-32)\n",">\n","> Ten real-valued features are computed for each cell nucleus:\n",">\n","> a) radius (mean of distances from center to points on the perimeter)\n",">\n","> b) texture (standard deviation of gray-scale values)\n",">\n","> c) perimeter\n",">\n","> d) area\n",">\n","> e) smoothness (local variation in radius lengths)\n",">\n","> f) compactness (perimeter^2 / area - 1.0)\n",">\n","> g) concavity (severity of concave portions of the contour)\n",">\n","> h) concave points (number of concave portions of the contour)\n",">\n","> i) symmetry\n",">\n","> j) fractal dimension (\"coastline approximation\" - 1)"]},{"cell_type":"markdown","metadata":{"id":"w1NLIkJMRP4U"},"source":["##Import das principais funções e leitura dos dados\n","\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wfg5H5k7QUoz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn import datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cz13V0q4Q5ZJ"},"outputs":[],"source":["data = datasets.load_breast_cancer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39H8czgiIvdT"},"outputs":[],"source":["df = pd.DataFrame(data.data, columns=data.feature_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"do_VDG4RJICz"},"outputs":[],"source":["target = pd.DataFrame(data.target, columns=['Target'])\n","df = pd.concat([df, target], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gE2hH2_8SHHZ"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K94v4s0lSNC4"},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iyj0P08tSR5M"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4JMYa2ZJSto"},"outputs":[],"source":["df.describe().T"]},{"cell_type":"markdown","metadata":{"id":"M9mSwwoqRbef"},"source":["## Treino de modelo de decision tree\n","---\n","\n","\n","Para treinar um modelo de regressão utilizaremos o pacote sklearn.\n","\n","\n","### Separação do banco entre treino e teste\n","O primeiro passo para se treinar um modelo é separar o banco entre treino e teste. Para isso utilizaremos a função train_test_split\n","\n","\n","``` python\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n","```\n","No exemplo acima X é um dataframe contendo as features do modelo e Y um dataframe com a variável target.\n","\n","\n","O parâmetro test_size controla o percentual de dados que será utilizado para teste.\n","\n","\n","O parâmetro random_state controla a aleatoriedade da geração do dado, permitindo que ao reexecutar o código seja gerado os mesmos bancos de treino e teste.\n","\n","\n","É importante separar o banco entre treino e teste, pois utilizaremos o banco de treino para treinar modelos e o banco de teste para avaliar os modelos.\n","\n","\n","### Treino do modelo\n","Agora que já possuímos os dados de treino e teste vamos treinar o nosso modelo XGBoost\n","\n","\n","``` python\n","from xgboost import XGBClassifier\n","model = XGBClassifier(objective='binary:logistic')\n","model.fit(X_train, Y_train)\n","```\n","\n","No código acima o objeto model é do tipo XGBClassifier, nele iremos fazer o ajuste do nosso modelo, realizar predições e também ficará armazenado a árvore e a importancia das features.\n","\n","\n","``` python\n","# Para fazer predições de classes\n","model.predict(X_test)\n","# Para fazer predições de probabilidade\n","model.predict_proba(X_test)\n","# Para acessar a importancia\n","model.feature_importances_\n","\n","```\n","\n","Alguns parâmetros da XGBClassifier:\n","* max_depth: profundidade da árvore. Default é 6.\n","* seed: semente para aleatoriedade.\n","* n_estimators*: número de árvores para construir. Default é 100.\n","* subsample: número de instancias para amostrar.\n","* colsample_bytree: número de colunas para amostrar ao construir uma árvore. Também é possível por level e por nó.\n","* objective: tipo de função de perda.\n","* learning_rate**: parâmetro de aprendizado do modelo. Quanto menor o valor mais árvores são necessarias. Default: 0.3\n","\n","\n","### Avaliação do modelo\n","Para avaliar o modelo treinado utilizaremos as métricas vistas na aula teórica.\n","\n","``` python\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay\n","\n","\n","# Métricas acurácia, precisão, recall, f1-score\n","print(classification_report(Y_test, Y_predit))\n","\n","\n","# Matriz de confusão\n","confusion_matrix(Y_test, Y_predit)\n","\n","\n","# AUC\n","roc_auc = roc_auc_score(Y_test, Y_predict)\n","fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n","display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n","display.plot()\n","```\n","\n","\n","Também é possível se obter cada uma das métricas do report\n","``` python\n","from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n","\n","\n","recall_score(Y_test, Y_predict, pos_label=1)\n","```\n","\n","\n","### Primeiro modelo\n","\n","---\n","\n","Exercício:\n","\n","\n","* Separe o banco entre treino e teste. Use 30% do banco para teste. Faça a quebra com todas as variáveis.\n","* Treine um modelo.\n","* Faça as análises de apuração do modelo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G4pgJuxgN_XX"},"outputs":[],"source":["X = pd.DataFrame(data.data, columns=data.feature_names)\n","Y = data.target"]},{"cell_type":"markdown","metadata":{"id":"idl1fuKB-1TJ"},"source":["#### Solução"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBs2wQ1dnmLJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"sztPnLqBUBm4"},"source":["Exercício:\n","* Treine um novo modelo porém com max_depth = 4\n","* Busca o limiar em que se obtém a melhor acurácia.\n","\n","Dica:\n","Para realizar a busca faça:\n","1. Gere o score de probabilidade\n","2. Percorra uma lista de valores de limiar e a cada valor calcule a acurácia\n","3. Obtenha o limiar com maior acurácia\n","\n","\n","Para acessar P(Y=1) faça predict_proba()[:, 1]"]},{"cell_type":"markdown","metadata":{"id":"265K8AE9UgWU"},"source":["#### Solução"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvlVSA9ono3u"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"92XsDKG0rGC2"},"source":["**Visualização da feature importance**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPM9tPBGrv9H"},"outputs":[],"source":["df = pd.DataFrame(model.feature_importances_.T, index=data.feature_names, columns=['Importancia'])\n","df.sort_values('Importancia', ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9v9YUWYsWd0"},"outputs":[],"source":["px.bar(df.sort_values('Importancia'))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNOWyyZTjHE+t9FVxJozUML","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
